{
 "cells": [
  {
   "cell_type": "code",
   "id": "6d6d4ad98451b440",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T15:25:59.517941Z",
     "start_time": "2024-11-06T15:25:59.190439Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.schema import Document\n",
    "pandarallel.initialize(progress_bar=True, verbose=0)\n",
    "tqdm.pandas()\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import random\n",
    "from src.utils import prepare_embedding_for_chromadb, prepare_embedding_for_comparison, split_text, cosine_similarity_score, calculate_mrr\n",
    "from src.model_m3 import EmbeddingModelM3"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'calculate_mrr' from 'data.src.utils' (/Users/arian/Documents/FHNW/npr/npr_hs_24/npr_mc1_new_hs24/npr-mc1-frfr/data/src/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 15\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mchromadb\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Settings\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m prepare_embedding_for_chromadb, prepare_embedding_for_comparison, split_text, cosine_similarity_score, calculate_mrr\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_m3\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EmbeddingModelM3\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'calculate_mrr' from 'data.src.utils' (/Users/arian/Documents/FHNW/npr/npr_hs_24/npr_mc1_new_hs24/npr-mc1-frfr/data/src/utils.py)"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T15:25:59.562498Z",
     "start_time": "2024-11-06T15:25:59.544680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('secrets.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line.startswith('openai'):\n",
    "            secret = line.split('=')[1].strip()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = secret\n",
    "\n",
    "storage_path = './data/chromadb'\n",
    "\n",
    "ai_client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T15:26:00.206302Z",
     "start_time": "2024-11-06T15:26:00.203182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('secrets.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line.startswith('api_token'):\n",
    "            token = line.split('=')[1].strip()\n",
    "\n",
    "embeddings = HuggingFaceEndpointEmbeddings(\n",
    "    model='http://100.67.185.22:8080',\n",
    "    huggingfacehub_api_token=token\n",
    ")\n",
    "\n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings,\n",
    "    breakpoint_threshold_type='standard_deviation'\n",
    ")"
   ],
   "id": "177fed536c391d76",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T15:26:01.818564Z",
     "start_time": "2024-11-06T15:26:00.555278Z"
    }
   },
   "cell_type": "code",
   "source": "embed_local = EmbeddingModelM3()",
   "id": "fc13248f96ba19c5",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T15:26:02.020046Z",
     "start_time": "2024-11-06T15:26:01.822329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_result = embed_local.embed_query(\"Hello, world!\") # local\n",
    "#query_result = embeddings.embed_query(\"Hello, world!\") # remote\n",
    "query_result[:3]"
   ],
   "id": "840feb7d2339660a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.026738807559013367, 0.42828133702278137, -0.6886834502220154]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Chunking with Semantic Chunker from langchain\n",
    "### Breakpoint: Standard Deviation"
   ],
   "id": "df839abd6bf257ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_parquet(\"data/clean_cleantech.parquet\")",
   "id": "555aebd342d637ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### generate \"eval_dataset\" from the \"df\" dataframe",
   "id": "b7ccab34b8a10335"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(3)",
   "id": "e6ee31bf918a09a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['chunks'] = df['content'].parallel_apply(lambda content: split_text([Document(content)], text_splitter))",
   "id": "af64f849d8c0de1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(3)",
   "id": "ef263715a1b4fe3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['chunk_size'] = df['chunks'].progress_apply(len)",
   "id": "426feab65131fd1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(3)",
   "id": "d50a821060768953",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['chunks'] = df['chunks'].progress_apply(lambda x: [t.page_content for t in x])",
   "id": "ce7585d47e357191",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.sample(5)",
   "id": "a9a5eefad6b8d205",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_parquet('data/processed/chunked_sd.parquet')",
   "id": "b21eb273c2794fc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_chunked = pd.read_parquet('data/processed/chunked_sd.parquet')",
   "id": "78e471fd626eca82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the file path\n",
    "file_path = 'data/eval_dataset/eval_dataset.parquet'\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.isfile(file_path):\n",
    "    # Load the dataset\n",
    "    df_chunked = pd.read_parquet('data/processed/chunked_sd.parquet')\n",
    "\n",
    "    # Define the evaluation dataset\n",
    "    eval_data = []\n",
    "\n",
    "    # Sample 100 random rows\n",
    "    sample_rows = df_chunked.sample(n=100, random_state=42)\n",
    "\n",
    "    # Iterate through the sampled rows\n",
    "    for _, row in tqdm(sample_rows.iterrows(), total=sample_rows.shape[0]):\n",
    "        doc_id = row['doc_id']\n",
    "        url = row['url']\n",
    "        \n",
    "        # Choose a random chunk from 'chunks' for the row\n",
    "        chunks = row['chunks']\n",
    "        if chunks:\n",
    "            used_chunk = random.choice(chunks)\n",
    "            \n",
    "            # Generate a question for the selected chunk\n",
    "            prompt = f\"Generate a question about the following text:\\n\\n{used_chunk}\"\n",
    "            \n",
    "            response = ai_client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            generated_question = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Append to evaluation dataset\n",
    "            eval_data.append({\n",
    "                'doc_id_df': doc_id,\n",
    "                'used_chunk': used_chunk,\n",
    "                'generated_question': generated_question,\n",
    "                'url': url\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    eval_dataset = pd.DataFrame(eval_data)\n",
    "\n",
    "    # Save to a new parquet file for later use\n",
    "    eval_dataset.to_parquet(file_path, index=False)\n",
    "else:\n",
    "    print(f\"The file '{file_path}' already exists.\")"
   ],
   "id": "b5b3d964304d52f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# remove empty chunks\n",
    "df_chunked['chunks'] = df_chunked['chunks'].progress_apply(lambda x: [y for y in x if len(y) > 0])"
   ],
   "id": "44c03b2a5ed27b55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Embed the Chunks\n",
    "### model: BAAI/bge-m3"
   ],
   "id": "1fb9b55946e5343c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# embed the chunks\n",
    "df_chunked['embeddings'] = df_chunked['chunks'].parallel_apply(embeddings.embed_documents)"
   ],
   "id": "c6853c4bf5f52da3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_chunked.head(3)",
   "id": "f02eb8d52267756b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# save the chunked and embedded data\n",
    "df_chunked.to_parquet('data/processed/chunked_sd_embedded.parquet')"
   ],
   "id": "3b33a97b2e70db89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setting up the ChromaDB\n",
    "preparing the embedded parquet fiel for ChromaDB"
   ],
   "id": "e3fd17512b7c5e02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_parquet('data/processed/chunked_sd_embedded.parquet')",
   "id": "b2d739d77d91a762",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(3)",
   "id": "13035ac396307334",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.embeddings[0]",
   "id": "4a0b53a5da26f654",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(df.embeddings[0]), type(df.embeddings[0][0])",
   "id": "a27b7102af3d3f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### preparing the data for ChromaDB",
   "id": "ce53f73160ac02d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Apply the function to prepare embeddings\n",
    "tqdm.pandas()\n",
    "df['embeddings'] = df['embeddings'].progress_apply(prepare_embedding_for_chromadb)\n",
    "\n",
    "# Check the result\n",
    "print(\"Sample embedding type and shape:\", type(df['embeddings'][0]), df['embeddings'][0].shape, df['embeddings'][0].dtype)"
   ],
   "id": "4029e2b051038cbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.embeddings[0]",
   "id": "46faaa412d97e602",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert 'date' column to string format\n",
    "df['date'] = df['date'].astype(str)"
   ],
   "id": "2353667ac76e2695",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure all doc_ids are unique by adding a suffix to duplicates\n",
    "df['doc_id'] = df['doc_id'].astype(str)  # Ensure IDs are strings\n",
    "df['doc_id'] = df.groupby('doc_id').cumcount().astype(str) + '_' + df['doc_id']"
   ],
   "id": "11c34e1f2ebbeb9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### saving",
   "id": "c551a858551dec10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Specify the storage path\n",
    "settings = Settings()\n",
    "\n",
    "# Initialize ChromaDB client with persistent settings\n",
    "client = chromadb.PersistentClient(path=storage_path, settings=settings)\n",
    "collection_name = \"energy_articles\"\n",
    "\n",
    "# Delete and recreate collection\n",
    "if collection_name in [col.name for col in client.list_collections()]:\n",
    "    client.delete_collection(collection_name)\n",
    "collection = client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "df['embeddings'] = df['embeddings'].progress_apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
    "\n",
    "# Insert data in batches\n",
    "batch_size = 10000\n",
    "for start in tqdm(range(0, len(df), batch_size)):\n",
    "    batch = df.iloc[start:start + batch_size]\n",
    "    \n",
    "    ids = batch['doc_id'].astype(str).tolist()\n",
    "    documents = batch['content'].tolist()\n",
    "    embeds = [embed.tolist() if isinstance(embed, np.ndarray) else embed for embed in batch['embeddings']]\n",
    "    metadatas = batch[['title', 'date', 'domain', 'url', 'language']].to_dict(orient='records')\n",
    "    \n",
    "    # Insert into ChromaDB collection\n",
    "    collection.add(\n",
    "        ids=ids,\n",
    "        documents=documents,\n",
    "        embeddings=embeds,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "\n",
    "print(\"Data successfully added to ChromaDB.\")"
   ],
   "id": "fa6e0104e17860ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Query similar documents\n",
    "question = 'In 2021, what were the top 3 states in the US in terms of total solar power generating capacity?'\n",
    "query_test = embeddings.embed_query(question)\n",
    "print(query_test[:3])"
   ],
   "id": "34c0174a507e00fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_embedding = prepare_embedding_for_chromadb(query_test)\n",
    "top_k = 5  # number of similar entries to retrieve\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding.tolist()],\n",
    "    n_results=top_k,\n",
    "    include=['documents', 'metadatas']\n",
    ")\n",
    "\n",
    "print(results)"
   ],
   "id": "cfc075e2ef67caf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Retrieval",
   "id": "cb8ad6e258a0588f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T15:26:07.586493Z",
     "start_time": "2024-11-06T15:26:07.579167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load eval dataset\n",
    "df_eval = pd.read_parquet('data/eval_dataset/eval_dataset.parquet')\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "client = chromadb.PersistentClient(path=storage_path, settings=settings)\n",
    "\n",
    "collection_name = \"energy_articles\"\n",
    "collection = client.get_collection(collection_name)"
   ],
   "id": "fc027a38916dc52a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T15:26:08.262579Z",
     "start_time": "2024-11-06T15:26:08.260228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"test_db = collection.get(include=['embeddings', 'documents', 'metadatas'], limit=1)\n",
    "print(test_db)\"\"\""
   ],
   "id": "4fd7c05f6b96f72b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"test_db = collection.get(include=['embeddings', 'documents', 'metadatas'], limit=1)\\nprint(test_db)\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T15:26:08.786530Z",
     "start_time": "2024-11-06T15:26:08.615481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_data_index = df_eval.sample(n=1)\n",
    "eval_question = eval_data_index.iloc[0][('generated_question')]\n",
    "eval_answer = eval_data_index.iloc[0]['used_chunk']\n",
    "article_url = eval_data_index.iloc[0]['url']\n",
    "document_id = eval_data_index.iloc[0]['doc_id_df']\n",
    "\n",
    "# Query text\n",
    "query_text = eval_question\n",
    "\n",
    "# Generate query embedding using the Hugging Face endpoint\n",
    "\n",
    "#query_embedding = embeddings.embed_query(query_text) # remote\n",
    "query_embedding = embed_local.embed_query(query_text) # local\n",
    "\n",
    "prepared_embeddings = prepare_embedding_for_chromadb(query_embedding)\n",
    "\n",
    "top_k = 20\n",
    "\n",
    "# Retrieve top 20 most relevant documents\n",
    "results = collection.query(\n",
    "    query_embeddings=[prepared_embeddings.tolist()],  # Query embedding\n",
    "    n_results=top_k,  # Number of similar documents to retrieve\n",
    "    include=['metadatas', 'embeddings', 'documents']  # Include documents and metadata in the results\n",
    ")"
   ],
   "id": "44f83484692026c9",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T15:26:21.419830Z",
     "start_time": "2024-11-06T15:26:11.016608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage for MRR calculation\n",
    "mrr = calculate_mrr(df_eval, collection, embed_local, top_k=20)"
   ],
   "id": "a3ecdd9b43c992b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank (MRR): 0.6352619047619048\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate a response with GPT-3.5-turbo",
   "id": "8218185dda872c48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare context with document references\n",
    "retrieved_text = \"\"\n",
    "content_test = \"\"\n",
    "if 'documents' in results and results['documents']:\n",
    "    for idx, doc in enumerate(results['documents'][0]):\n",
    "        # Access the document's metadata and ID\n",
    "        metadata = results['metadatas'][0][idx]  # Access metadata for each document\n",
    "        doc_id = results['ids'][0][idx]  # Retrieve doc_id directly from results\n",
    "        title = metadata.get(\"title\", \"Untitled Document\")\n",
    "        url = metadata.get(\"url\", \"URL not available\")\n",
    "        content = doc\n",
    "        content_test += content\n",
    "\n",
    "        # Build the retrieved text with document references\n",
    "        retrieved_text += (\n",
    "            f\"Document {idx + 1} - ID: {doc_id}\\n\"\n",
    "            f\"Title: {title}\\n\"\n",
    "            f\"URL: {url}\\n\"\n",
    "            f\"Content: {content}\\n\\n\"\n",
    "        )\n",
    "else:\n",
    "    print(\"No documents found in query results.\")\n",
    "    \n",
    "#print(retrieved_text)\n",
    "\n",
    "# Create a system message with instructions for the assistant\n",
    "system_message = \"\"\"\n",
    "You are a knowledgeable assistant. Based on the information from the documents provided by the user, answer the question in a detailed and informative way. In your answer, refer to specific documents by mentioning their titles, URLs, and IDs when relevant.\n",
    "\n",
    "At the end of your answer, please provide a separate \"Sources\" section, listing all document titles, IDs, and URLs you referenced, even if they were only indirectly useful.\n",
    "\"\"\"\n",
    "\n",
    "# Construct the prompt as the user's message\n",
    "prompt = f\"\"\"\n",
    "Question: {query_text}\n",
    "\n",
    "Documents:\n",
    "{retrieved_text}\n",
    "\n",
    "Please structure your answer as follows:\n",
    "Answer:\n",
    "(Your detailed answer here, with references to specific documents as needed)\n",
    "\n",
    "Sources:\n",
    "- Document N: documnet_id document_title, document_url\n",
    "- Document N: documnet_id, document_title, document_url\n",
    "- Document N: documnet_id, document_title, document_url\n",
    "(Include every document you referred to in the answer)\n",
    "\"\"\"\n",
    "\n",
    "# Generate a response with GPT-3.5-turbo\n",
    "response = ai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "generated_response = response.choices[0].message.content\n",
    "\n",
    "# Print the generated response\n",
    "print(f'Used question: {eval_question}\\nURL: {article_url}\\n Used chunk for question: {eval_answer}\\n Document ID: {document_id}')\n",
    "print('-'*40)\n",
    "print(generated_response)\n",
    "print('-'*40)"
   ],
   "id": "f60c730af332e4cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prepare relevant embedding\n",
    "relevant_embedding = embed_local.embed_query(eval_answer)  # Assume this is the embedding for the relevant chunk\n",
    "prepared_relevant_embedding = prepare_embedding_for_comparison(relevant_embedding)\n",
    "\n",
    "# Retrieve embeddings from results and convert them to numpy arrays\n",
    "retrieved_embeddings = [np.array(doc_embed) for doc_embed in results['embeddings'][0]]\n",
    "\n",
    "# Ensure retrieved embeddings are prepared (consistent dimensions)\n",
    "retrieved_embeddings = [prepare_embedding_for_comparison(embed) for embed in retrieved_embeddings]\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarities = cosine_similarity_score(retrieved_embeddings, prepared_relevant_embedding)\n",
    "\n",
    "# Print top similarities\n",
    "print(\"Top cosine similarity scores with the relevant chunk:\")\n",
    "for idx, score in enumerate(similarities.flatten()):\n",
    "    print(f\"Document {idx + 1}: Cosine Similarity = {score}\")"
   ],
   "id": "627ad38ba06db87c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ragas import EvaluationDataset, evaluate\n",
    "from ragas.metrics import ContextPrecision, Faithfulness, AnswerRelevancy, ContextRecall\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM for metrics that require it\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-3.5-turbo\"))\n",
    "\n",
    "# Prepare the data with required columns\n",
    "data = [\n",
    "    {\n",
    "        \"question\": row[\"question\"],\n",
    "        \"user_input\": row[\"question\"],  # Same as the question\n",
    "        \"context\": [row[\"relevant_chunk\"]],  # Relevant context or chunk\n",
    "        \"retrieved_contexts\": [content_test],  # Retrieved context(s)\n",
    "        \"response\": response.choices[0].message.content,  # Use actual response if available\n",
    "        \"reference\": eval_answer  # Replace with ground truth if available\n",
    "    }\n",
    "    for _, row in df_eval.iterrows()\n",
    "]\n",
    "\n",
    "# Create the EvaluationDataset\n",
    "eval_dataset = EvaluationDataset.from_list(data)\n",
    "\n",
    "# Define metrics to use for evaluation\n",
    "metrics = [\n",
    "    ContextPrecision(),\n",
    "    Faithfulness(llm=evaluator_llm),\n",
    "    AnswerRelevancy(llm=evaluator_llm),\n",
    "    ContextRecall()\n",
    "]\n",
    "\n",
    "# Run the evaluation\n",
    "results_eval = evaluate(eval_dataset, metrics=metrics)"
   ],
   "id": "c9714fab2353c9af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_results = results.to_pandas()\n",
    "df_results"
   ],
   "id": "3f77dfa9ef6fe2d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "809a119d9596a014",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
