{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is properly detected\n",
    "print(torch.cuda.device_count())  # Number of available CUDA devices\n",
    "print(torch.cuda.get_device_name(0))  # Name of the first CUDA device"
   ],
   "id": "9cbb07249f6efda1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import langid\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ],
   "id": "d671c4661f4f8e8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_csv('data/raw/cleantech_media_dataset_v2_2024-02-23.csv')",
   "id": "92ebc56d5b9ad919",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "9a281d92dd0d2131",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "id": "1924363bfcc7d56c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# remove author column\n",
    "df = df.drop(columns=['author'])\n",
    "\n",
    "# rename column Unamed: 0 to doc_id\n",
    "df = df.rename(columns={'Unnamed: 0': 'doc_id'})"
   ],
   "id": "86d29927f28ba7dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# convert date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ],
   "id": "50b67180b869fa08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "4e9a52c780c922a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['content'][0]",
   "id": "11227deb24f37f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if in the 'content' column are multiple lists per entry\n",
    "df[\"content\"].apply(lambda x: isinstance(x, list)).sum()"
   ],
   "id": "9e309f803c74d1d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"content\"] = df[\"content\"].apply(eval)\n",
    "\n",
    "df = df.explode(\"content\")"
   ],
   "id": "7bfa517efae46d1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.shape",
   "id": "f75aae9a2b07eb09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# removing empty strings\n",
    "(df['content'].str.strip() == '').sum()"
   ],
   "id": "48de5588aa98ddaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df['content'].str.strip() == '']",
   "id": "53776b049d770088",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df[(df[\"content\"].str.strip() != \"\")]",
   "id": "9d5aea3ce4853f91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# eliminating duplicate entries\n",
    "df[df.duplicated()].sort_values(\"content\")"
   ],
   "id": "df8ec8d74b30a6d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df[~df.duplicated()]",
   "id": "34627563195719de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Advanced Text cleaning Process\n",
   "id": "ad7fee7b22e22cea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ftfy import fix_text, fix_encoding\n",
    "from unstructured.cleaners.core import replace_unicode_quotes\n",
    "from transformers import pipeline\n",
    "import torch"
   ],
   "id": "e244aa5e309476dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.set_float32_matmul_precision('medium')",
   "id": "1dc7c54100ae7b95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['content'] = (\n",
    "    df['content']\n",
    "    .apply(fix_text)\n",
    "    .apply(fix_encoding)\n",
    "    .apply(replace_unicode_quotes)\n",
    ")"
   ],
   "id": "5e79527d75e98735",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df['content'][0])",
   "id": "1a87740a2811ca63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check what language the content is\n",
    "df['language'] = df['content'].parallel_apply(lambda x: langid.classify(x)[0])\n",
    "df['language'].value_counts()"
   ],
   "id": "beafcdcd18c79c1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df['language'] == 'fr']",
   "id": "6669e1f65f155e75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print all languages that are not english in a list\n",
    "non_english = df[df[\"language\"] != \"en\"]\n",
    "non_english[\"language\"].unique()"
   ],
   "id": "954fa8dda683ad32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "texts = [\n",
    "    [\n",
    "        \"[ 1 ] see for example: harvey et al 2021, larson et al. 2020, haley et al. 2019, larsen et al. 2019 and ipcc 2018.\"\n",
    "    ],\n",
    "    [\n",
    "        \"qatar petroleum ( qp) is targeting aggressive cuts in its greenhouse gas emissions as it prepares to launch phase 2 of its planned 48 million ton per year lng expansion. in its latest sustainability report published on wednesday, qp said its goals include  reducing the emissions intensity of qatar's lng facilities by 25% and of its upstream facilities by at least 15%.  the company is also aiming to reduce gas flaring intensity across its upstream facilities by more than 75% and has raised its carbon capture and storage ambitions from 5 million tons/yr to 7 million tons/yr by 2027. about 2.2 million tons/yr of the carbon capture goal will come from the 32 million ton/yr phase 1 of the lng expansion, also known as the north field east project. a further 1.1 million tons/yr will come from phase 2, known as the north field south project, which will raise qatar's lng capacity by a further 16 million tons/yr. qatar currently has an lng production capacity of around 78 million tons/yr and is eyeing a phased expansion to 126 million tons/yr. qp says it should be able to eliminate routine gas flaring by 2030, with methane emissions limited  by setting a methane intensity target of 0.2% across all facilities by 2025.  the company also plans to build some 1.6 gigawatts of solar energy capacity by 2025, half of which should come from the siraj solar power project next year ( eif jan.22'20). until this month, there had been little news about phase 2 of qatar's massive lng expansion. but mcdermott international said last week that it had been awarded the front-end engineering and design contract for five offshore wellhead platforms ( lngi jan.12'21). bids for construction of all four trains for phase 1 of the lng expansion were submitted in september ( lngi sep.15'20). but qp judged them to be too expensive and none met its targeted 50-week construction schedule. shortlisted contractors were asked to look for cost savings and submit new bids. the contract, which consultancy rystad estimates to be worth around $ 35 billion, is expected to be awarded by mar. 31. shortly after the construction contract is awarded, qp is expected to select foreign investments partners to take stakes of up to 30% in the phase 1 trains. exxon mobil, royal dutch shell, total, chevron, conocophillips and eni have been shortlisted. qp has repeatedly said that it is prepared to proceed without international investment partners if it determines that the offers it receives are not sufficiently attractive. but the shortlisted companies are expected to bid aggressively for what is expected to be the world's lowest-cost and most environmentally friendly lng ( lngi nov.9'20). rafiq latta, nicosia\"\n",
    "    ],\n",
    "    [\n",
    "        \"government actions in opposition to oil and gas introduce a range of potentially dangerous insecurities. we have been there, and done all of this before with oil and seen the consequences. that past experience, in large part, underlies notions of the criticality of minerals.\"\n",
    "    ],\n",
    "    [\n",
    "        \"a: we’ re not going to be anywhere near the pace and scale that we need to be in this clean energy transition. we need to accelerate even further with very robust, well thought-through government levers, funding streams, authorities and regulation, as well as private sector leadership.\"\n",
    "    ],\n",
    "    [\n",
    "        \"“ [ exploration is ] where there might be the best opportunity right now to really create some long-term substantial returns, because there’ s great opportunity, ” said apa ceo john christmann.\"\n",
    "    ],\n",
    "    [\n",
    "        \"“ i don't think it's going to be explicit, ” he said. “ i think it's not necessarily going to be the first or second thing. but probably the third [ or ] fourth thing. what we're observing is in the due diligence process, understanding if this deal is going to be accretive day one to the esg profile. ”\"\n",
    "    ],\n",
    "    [\n",
    "        \"ørsted has taken a final investment decision ( fid) on its first renewable hydrogen project, with plans to launch the facility later this year.\"\n",
    "    ],\n",
    "    [\n",
    "        \"gradient comfort – about us [ online ] available at: https: //www.gradientcomfort.com/pages/about-us\"\n",
    "    ],\n",
    "    [\"image credit: mariskavegter/shutterstock.com\"],\n",
    "    [\"related topics: carbon footprint renewable diesel utility\"],\n",
    "    [\"4. zero emissions power\"],\n",
    "    [\"برك المياه تقفل أوتوستراد # زوق مصبح # ملجق # لبنان pic.twitter.com/8njf85yq00\"],\n",
    "    [\"https: //t.co/kmucrzhy6z pic.twitter.com/ovbxoxseju\"],\n",
    "    [\"— patrick pouyanné ( @ ppouyanne) april 11, 2021\"],\n",
    "    [\n",
    "        \"( ofgem assume 2.9mwh per typical 🏠) ( ccc expect ⚡️increase for 🚗🚐🚛from 9 twh in 2022 to 47twh to 2030) https: //t.co/acoaky8tlj\"\n",
    "    ],\n",
    "    [\"ford mustang mach-e. photo by zach shahan | cleantechnica.\"],\n",
    "    [\"youtube: https: //www.youtube.com/c/bluettiofficial\"],\n",
    "    [\n",
    "        \"volkswagen id. buzz concept electric van, aka hippie bus. image courtesy of volkswagen.\"\n",
    "    ],\n",
    "    [\"issn © 1532-1231 | issn © 2577-9877 | issn © 1532-1266 |\"],\n",
    "    [\"your password *\"],\n",
    "    [\"reset password\"],\n",
    "    [\"decentralise\"],\n",
    "]"
   ],
   "id": "cbb314017bb81d9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "positive_labels = [\"Text Paragraph\", \"Text Report\", \"Text Blog\"]\n",
    "negative_labels = [\"Reference\", \"Link\", \"Topic Tags\", \"Image Source\", \"Image Credits\", \"Password\", \"EmailAddress\",\n",
    "                   \"Cookie Consent\", \"Noisy Text\", \"Social Media Refernce\", \"Single Word\", \"Copyright\"]\n",
    "\n",
    "pos_score = lambda df: [sum(y[i] for i, t in enumerate(x) if t in positive_labels) for x, y in\n",
    "                        zip(df[\"labels\"], df[\"scores\"])]\n",
    "\n",
    "classes_verbalized = positive_labels + negative_labels"
   ],
   "id": "8972094e5236891d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "zeroshot_classifier_v3 = pipeline(\n",
    "    \"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\", device_map=\"cuda\"\n",
    ")\n",
    "zeroshot_classifier_m3 = pipeline(\n",
    "    \"zero-shot-classification\", model=\"MoritzLaurer/bge-m3-zeroshot-v2.0\", device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "# Initialize a list to store DataFrames\n",
    "df_v3 = []\n",
    "df_m3 = []\n",
    "\n",
    "# Process each text with both models\n",
    "for text in texts:\n",
    "    output_v3 = zeroshot_classifier_v3(text, classes_verbalized, multi_label=False)\n",
    "\n",
    "    # Create DataFrames from the outputs\n",
    "    df_output_v3 = pd.DataFrame(output_v3)\n",
    "\n",
    "    # Append each DataFrame to the list\n",
    "    df_v3.append(df_output_v3)\n",
    "\n",
    "    # add column \"model\"\n",
    "    df_output_v3[\"model\"] = \"v3\"\n",
    "\n",
    "# Process each text with both models\n",
    "for text in texts:\n",
    "    output_m3 = zeroshot_classifier_m3(text, classes_verbalized, multi_label=False)\n",
    "\n",
    "    # Create DataFrames from the outputs\n",
    "    df_output_m3 = pd.DataFrame(output_m3)\n",
    "\n",
    "    # Append each DataFrame to the list\n",
    "    df_m3.append(df_output_m3)\n",
    "\n",
    "    # add column \"model\"\n",
    "    df_output_m3[\"model\"] = \"m3\"\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "df_v3 = pd.concat(df_v3)\n",
    "df_m3 = pd.concat(df_m3)"
   ],
   "id": "e470d672dae8c97e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_v3.to_csv('data/df_v3.csv', index=False)\n",
    "df_m3.to_csv('data/df_m3.csv', index=False)"
   ],
   "id": "b5929f92520fe5ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_v3 = pd.read_csv('data/df_v3.csv')\n",
    "df_m3 = pd.read_csv('data/df_m3.csv')"
   ],
   "id": "6ebd34202bd40748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_v3.info()",
   "id": "d0349c183b6e48ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Assuming df_v3 and df_m3 are already defined and contain the data as described\n",
    "\n",
    "\n",
    "# Function to convert string representation of lists into actual lists\n",
    "def str_to_list(s):\n",
    "    return ast.literal_eval(s)\n",
    "\n",
    "\n",
    "# Convert string representations in both DataFrames\n",
    "df_v3[\"labels\"] = df_v3[\"labels\"].apply(str_to_list)\n",
    "df_v3[\"scores\"] = df_v3[\"scores\"].apply(str_to_list)\n",
    "df_m3[\"labels\"] = df_m3[\"labels\"].apply(str_to_list)\n",
    "df_m3[\"scores\"] = df_m3[\"scores\"].apply(str_to_list)\n",
    "\n",
    "# Ensure both dataframes are aligned by sequence or by an appropriate key\n",
    "# This step assumes the sequences align perfectly and are in the same order.\n",
    "for idx in range(max(len(df_v3), len(df_m3))):\n",
    "    # Print the sequence\n",
    "    if idx < len(df_v3):\n",
    "        print(\"Sequence from df_v3:\", df_v3.iloc[idx][\"sequence\"])\n",
    "    elif idx < len(df_m3):  # If no matching sequence in df_v3\n",
    "        print(\"Sequence from df_m3:\", df_m3.iloc[idx][\"sequence\"])\n",
    "\n",
    "    plt.figure(figsize=(12, 6))  # Set the figure size for each pair of plots\n",
    "\n",
    "    # Plot for model v3 if available\n",
    "    if idx < len(df_v3):\n",
    "        labels_v3 = df_v3.iloc[idx][\"labels\"]\n",
    "        scores_v3 = df_v3.iloc[idx][\"scores\"]\n",
    "        model_v3 = df_v3.iloc[idx][\"model\"]\n",
    "\n",
    "        plt.subplot(1, 2, 1)  # Left plot for v3 model\n",
    "        plt.bar(labels_v3, scores_v3, color=\"blue\")\n",
    "        plt.title(f\"Model: {model_v3}\")\n",
    "        plt.xlabel(\"Labels\")\n",
    "        plt.ylabel(\"Scores\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    # Plot for model m3 if available\n",
    "    if idx < len(df_m3):\n",
    "        labels_m3 = df_m3.iloc[idx][\"labels\"]\n",
    "        scores_m3 = df_m3.iloc[idx][\"scores\"]\n",
    "        model_m3 = df_m3.iloc[idx][\"model\"]\n",
    "\n",
    "        plt.subplot(1, 2, 2)  # Right plot for m3 model\n",
    "        plt.bar(labels_m3, scores_m3, color=\"green\")\n",
    "        plt.title(f\"Model: {model_m3}\")\n",
    "        plt.xlabel(\"Labels\")\n",
    "        plt.ylabel(\"Scores\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    plt.tight_layout(\n",
    "        rect=[0, 0.03, 1, 0.95]\n",
    "    )  # Adjust layout to make room for the main title\n",
    "    plt.show()"
   ],
   "id": "1c4d2389a0689b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(df_v3[\"labels\"][0])\n",
    "print(df_v3[\"scores\"][0])"
   ],
   "id": "b20036d8e864689f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_v3[\"pos_prob\"] = pos_score(df_v3)\n",
    "df_m3[\"pos_prob\"] = pos_score(df_m3)"
   ],
   "id": "d1ed7a9ffc148b6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_v3",
   "id": "eab7f1b77f9945c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_v3[df_v3[\"pos_prob\"] > 0.6][\"sequence\"].tolist()",
   "id": "80e62df4c1fb9b81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_m3[df_m3[\"pos_prob\"] > 0.5][\"sequence\"].tolist()",
   "id": "f23afecb05a91837",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "zeroshot_classifier_v3.model = zeroshot_classifier_v3.model.eval()",
   "id": "769a1a1e70f8560e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "id": "9f2bdcf84bb02dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['classification_prediction'] = zeroshot_classifier_v3(df['content'].tolist(),\n",
    "                                                         classes_verbalized,\n",
    "                                                         multi_label=False,\n",
    "                                                         torch_dtype=torch.bfloat16,\n",
    "                                                         batch_size=96)"
   ],
   "id": "69b0fde902bcc248",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_parquet('data/classified.parquet')",
   "id": "c7a530c43e2ff5f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data = pd.read_parquet('data/classified.parquet')",
   "id": "b25aabbb5bf2a67f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.head(5)",
   "id": "eb8a71fa822a09c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data['labels'] = data['classification_prediction'].parallel_apply(lambda x: x['labels'])",
   "id": "91feebb676e51293",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data['scores'] = data['classification_prediction'].parallel_apply(lambda x: x['scores'])",
   "id": "aa73aa34eac99b34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data['pos_score'] = pos_score(data)",
   "id": "2e195b174ee3db73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data = data[data[\"pos_score\"] > 0.65]",
   "id": "93d1f80df01d91f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.shape",
   "id": "6c1bdbc56b94105b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"from tqdm import tqdm\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import json\n",
    "\n",
    "tagger = SequenceTagger.load(\"flair/ner-english-ontonotes-large\").eval()\n",
    "\n",
    "t = [Sentence(x) for x in tqdm(data[\"content\"].tolist()) if x]\n",
    "\n",
    "w = [tagger.predict(x, mini_batch_size=32, return_probabilities_for_all_classes=True) for x in tqdm(t) if x]\n",
    "w = [x.get_spans('ner').to_dict() for x in tqdm(w)]\n",
    "\n",
    "data[\"ner\"] = data[\"ner\"].apply(lambda x: x.tolist()).apply(json.dumps)\"\"\""
   ],
   "id": "dae20f0ae91a86e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import json\n",
    "\n",
    "# Load the tagger and set to evaluation mode\n",
    "tagger = SequenceTagger.load(\"flair/ner-english-ontonotes-large\").eval()\n",
    "\n",
    "# Create a list of Sentence objects if the content is not empty\n",
    "t = [Sentence(x) for x in tqdm(data[\"content\"].tolist()) if x]\n",
    "\n",
    "# Predict in-place for each sentence, handling them in batches\n",
    "for sentence in tqdm(t):\n",
    "    tagger.predict(sentence, mini_batch_size=32, return_probabilities_for_all_classes=True)\n",
    "\n",
    "# Convert the sentence data to dictionaries\n",
    "w = [x.to_dict(tag_type='ner') for x in tqdm(t) if x.get_spans('ner')]\n",
    "\n",
    "# Assuming you want to store these in a dataframe, you might do something like:\n",
    "data[\"ner\"] = [json.dumps([span.to_dict() for span in sentence.get_spans('ner')]) for sentence in t]\n",
    "\n",
    "# Assuming the DataFrame already exists and you're appending new data:\n",
    "data[\"ner\"] = data[\"ner\"].apply(json.loads)"
   ],
   "id": "3d0e7baedd65c4d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from unstructured.cleaners import core\n",
    "from functools import partial\n",
    "\n",
    "data[\"content\"] = data[\"content\"].apply(\n",
    "    partial(core.clean, extra_whitespace=True, dashes=True, bullets=True)\n",
    ")"
   ],
   "id": "31562a5d9b2be6ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.head(5)",
   "id": "bc1d11cea3c3917e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(data[\"content\"][2])",
   "id": "ef79c7a0569f0cc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.to_parquet(\"data/processed/clean_cleantech.parquet\", index=False)",
   "id": "5e68766e26f2ee1a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
